# Conversation Summarizer
This project addresses the task of conversation summarization by fine-tuning BART on the SAMSum dataset. We compare its performance with Gemini (via few-shot prompting), using ROUGE and BERTScore for evaluation.

Repository Contents:

- **conversation_summ.ipynb**: notebook for fine-tuning of Facebookâ€™s BART model on the SAMSum dataset.
- **test_scores**: notebook for evaluating the performance of the fine-tuned model and comparing it with Gemini Flash 2.0. The evaluation is based on ROUGE and BERTScore.
- The summaries generated by the fine-tuned model are saved in **conversation_summ_eval.csv** 
- The summaries generated by Gemini (via few-shot prompting) are saved in **conv_summ_eval_fewshot**.

How to run: 
Run **conversation_summ.ipynb** first to fine-tune the model. Then execute **test_scores.ipynb** to generate evaluation metrics and compare results with Gemini.

For further details and a comprehensive analysis of the results, please refer to the final report included in this repository.
